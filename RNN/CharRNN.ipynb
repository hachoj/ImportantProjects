{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab length is : 61\n",
      "{'\\n': 0, ' ': 1, '!': 2, \"'\": 3, '(': 4, ')': 5, ',': 6, '-': 7, '.': 8, ':': 9, ';': 10, '?': 11, 'A': 12, 'B': 13, 'C': 14, 'D': 15, 'E': 16, 'F': 17, 'G': 18, 'H': 19, 'I': 20, 'J': 21, 'K': 22, 'L': 23, 'M': 24, 'N': 25, 'O': 26, 'P': 27, 'R': 28, 'S': 29, 'T': 30, 'U': 31, 'V': 32, 'W': 33, 'Y': 34, 'a': 35, 'b': 36, 'c': 37, 'd': 38, 'e': 39, 'f': 40, 'g': 41, 'h': 42, 'i': 43, 'j': 44, 'k': 45, 'l': 46, 'm': 47, 'n': 48, 'o': 49, 'p': 50, 'q': 51, 'r': 52, 's': 53, 't': 54, 'u': 55, 'v': 56, 'w': 57, 'x': 58, 'y': 59, 'z': 60} {0: '\\n', 1: ' ', 2: '!', 3: \"'\", 4: '(', 5: ')', 6: ',', 7: '-', 8: '.', 9: ':', 10: ';', 11: '?', 12: 'A', 13: 'B', 14: 'C', 15: 'D', 16: 'E', 17: 'F', 18: 'G', 19: 'H', 20: 'I', 21: 'J', 22: 'K', 23: 'L', 24: 'M', 25: 'N', 26: 'O', 27: 'P', 28: 'R', 29: 'S', 30: 'T', 31: 'U', 32: 'V', 33: 'W', 34: 'Y', 35: 'a', 36: 'b', 37: 'c', 38: 'd', 39: 'e', 40: 'f', 41: 'g', 42: 'h', 43: 'i', 44: 'j', 45: 'k', 46: 'l', 47: 'm', 48: 'n', 49: 'o', 50: 'p', 51: 'q', 52: 'r', 53: 's', 54: 't', 55: 'u', 56: 'v', 57: 'w', 58: 'x', 59: 'y', 60: 'z'}\n"
     ]
    }
   ],
   "source": [
    "text = open('shakespeare.txt', 'r').read()\n",
    "stoi = {ch: i for i, ch in enumerate(sorted(list(set(text))))}\n",
    "itos = {i: ch for ch, i in stoi.items()}\n",
    "encode = lambda s: [stoi[c] for c in s]\n",
    "decode = lambda l: ''.join([itos[i] for i in l])\n",
    "vcb = len(stoi)\n",
    "print(f\"Vocab length is : {vcb}\")\n",
    "import random\n",
    "\n",
    "class dataloader:\n",
    "    def __init__(self):\n",
    "        self.data = torch.tensor(encode(text))\n",
    "        self.train_counter = 0\n",
    "        self.val_counter = 0\n",
    "    def next_batch(self, dataset):\n",
    "        n = int(len(self.data) * 0.9)\n",
    "        xt = self.data[self.train_counter:84000 + self.train_counter].view(-1, 100)\n",
    "        yt = self.data[1 + self.train_counter:84001 + self.train_counter].view(-1, 100)\n",
    "        xv = self.data[self.val_counter + 84000:self.val_counter + 94000].view(-1, 100)\n",
    "        yv = self.data[self.val_counter + 84001:self.val_counter + 94001].view(-1, 100)\n",
    "        if dataset == 'train':\n",
    "            self.train_counter += random.randint(1, 100)\n",
    "            if self.train_counter + len(self.data) >= 84000:\n",
    "                self.train_counter = 0\n",
    "            return xt, yt\n",
    "        elif dataset == 'val':\n",
    "            self.val_counter += random.randint(1, 100)\n",
    "            if self.val_counter + len(self.data) >= 94000:\n",
    "                self.val_counter = 0\n",
    "            return xv, yv\n",
    "        else:\n",
    "            raise Exception(\"Invalid dataset\")\n",
    "print(stoi, itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([94275])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(encode(text)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "@dataclass\n",
    "class Config:\n",
    "    n_embd = 256\n",
    "    hidden_size = 512\n",
    "    n_hidden = 3\n",
    "    vocab_size = 61\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "class ShakespeareRNN(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(ShakespeareRNN, self).__init__()\n",
    "        self.config = config\n",
    "        self.embedding = nn.Embedding(config.vocab_size, config.n_embd)\n",
    "        self.RNN = nn.ModuleDict(dict(\n",
    "            inputs = nn.Linear(config.n_embd, config.hidden_size),\n",
    "            hidden = nn.Linear(config.hidden_size, config.hidden_size),\n",
    "            hidden2 = nn.Linear(config.hidden_size, config.hidden_size),\n",
    "            hidden3 = nn.Linear(config.hidden_size, config.hidden_size),\n",
    "            output = nn.Linear(config.hidden_size, config.vocab_size)\n",
    "        ))\n",
    "    def forward(self, x, hidden_state, target=None):\n",
    "        x = self.embedding(x)\n",
    "        x = F.gelu(self.RNN['inputs'](x) + self.RNN['hidden'](hidden_state))\n",
    "        x = x + F.gelu(self.RNN['hidden2'](x))\n",
    "        x = x + F.gelu(self.RNN['hidden3'](x))\n",
    "        hidden_state = x\n",
    "        output = self.RNN['output'](x)\n",
    "        loss = None\n",
    "        if target is not None:\n",
    "            loss = F.cross_entropy(output, target)\n",
    "        return output, hidden_state, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt: Cosine learning rate decay function\n",
    "import math\n",
    "\n",
    "def cosine_lr_decay(optimizer, step, total_steps, lr_max, lr_min):\n",
    "    \"\"\"\n",
    "    Cosine learning rate decay function.\n",
    "\n",
    "    Args:\n",
    "        optimizer: The optimizer whose learning rate is to be decayed.\n",
    "        step: The current training step.\n",
    "        total_steps: The total number of training steps.\n",
    "        lr_max: The maximum learning rate.\n",
    "        lr_min: The minimum learning rate.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    progress = step / total_steps\n",
    "    lr = lr_min + (lr_max - lr_min) * (0.5 * (1 + math.cos(progress * math.pi)))\n",
    "    return lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of parameters in the model is: 966461\n"
     ]
    }
   ],
   "source": [
    "model = ShakespeareRNN(Config()).to(Config().device)\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"The number of parameters in the model is: {num_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0/3000], Loss: 2.268352507352829, Val Loss: 1.9106521093845368\n",
      "Epoch: [100/3000], Loss: 1.1352999180555343, Val Loss: 2.070452616214752\n",
      "Epoch: [200/3000], Loss: 1.076314741373062, Val Loss: 2.3088936495780943\n",
      "Epoch: [300/3000], Loss: 1.0381871038675308, Val Loss: 2.333832850456238\n",
      "Epoch: [400/3000], Loss: 1.0257850539684297, Val Loss: 2.346718285083771\n",
      "Epoch: [500/3000], Loss: 0.9982595890760422, Val Loss: 2.439258476495743\n",
      "Epoch: [600/3000], Loss: 0.978696905374527, Val Loss: 2.4511160027980803\n",
      "Epoch: [700/3000], Loss: 0.9535985660552978, Val Loss: 2.554341630935669\n",
      "Epoch: [800/3000], Loss: 0.9282117390632629, Val Loss: 2.589925948381424\n",
      "Epoch: [900/3000], Loss: 0.9032047098875046, Val Loss: 2.660477876663208\n",
      "Epoch: [1000/3000], Loss: 0.8880662375688553, Val Loss: 2.6788816404342652\n",
      "Epoch: [1100/3000], Loss: 0.8575604856014252, Val Loss: 2.7501745557785036\n",
      "Epoch: [1200/3000], Loss: 0.8405070346593857, Val Loss: 2.8059444427490234\n",
      "Epoch: [1300/3000], Loss: 0.8075519415736199, Val Loss: 2.8365404427051546\n",
      "Epoch: [1400/3000], Loss: 0.7804212659597397, Val Loss: 2.970718072652817\n",
      "Epoch: [1500/3000], Loss: 0.7603779241442681, Val Loss: 3.011628499031067\n",
      "Epoch: [1600/3000], Loss: 0.7286731937527656, Val Loss: 3.1594735884666445\n",
      "Epoch: [1700/3000], Loss: 0.6977145111560822, Val Loss: 3.210602650642395\n",
      "Epoch: [1800/3000], Loss: 0.6743083322048187, Val Loss: 3.273850975036621\n",
      "Epoch: [1900/3000], Loss: 0.638896349966526, Val Loss: 3.420697340965271\n",
      "Epoch: [2000/3000], Loss: 0.6212398546934128, Val Loss: 3.4941527104377745\n",
      "Epoch: [2100/3000], Loss: 0.5980400902032852, Val Loss: 3.591373941898346\n",
      "Epoch: [2200/3000], Loss: 0.5751140969991684, Val Loss: 3.651680977344513\n",
      "Epoch: [2300/3000], Loss: 0.5515818230807781, Val Loss: 3.7653974318504333\n",
      "Epoch: [2400/3000], Loss: 0.5370117548108101, Val Loss: 3.846058850288391\n",
      "Epoch: [2500/3000], Loss: 0.5252970971167088, Val Loss: 3.9670392370223997\n",
      "Epoch: [2600/3000], Loss: 0.5099734035134316, Val Loss: 4.063283479213714\n",
      "Epoch: [2700/3000], Loss: 0.5013272634148598, Val Loss: 4.085649826526642\n",
      "Epoch: [2800/3000], Loss: 0.49041498109698295, Val Loss: 4.06409289598465\n",
      "Epoch: [2900/3000], Loss: 0.4840464110672474, Val Loss: 4.095321617126465\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "num_epochs = 3000\n",
    "dl = dataloader()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "first_hidden  = torch.zeros(1, model.config.hidden_size).to(model.config.device)\n",
    "hidden_state = first_hidden\n",
    "tlossi = []\n",
    "vlossi = []\n",
    "lri = []\n",
    "gradients = []\n",
    "for epoch in range(num_epochs):\n",
    "    x, y = dl.next_batch('train')\n",
    "    xv, yv = dl.next_batch('val')\n",
    "    x, y = x.to(model.config.device), y.to(model.config.device)\n",
    "    xv, yv = xv.to(model.config.device), yv.to(model.config.device)\n",
    "    total_loss = 0\n",
    "    val_loss = 0\n",
    "    epoch_loss = 0\n",
    "    lr = cosine_lr_decay(optimizer, epoch, num_epochs, 0.001, 0.00001)\n",
    "    # lr = 0.0001\n",
    "    lri.append(lr)\n",
    "    for i in range(100):\n",
    "        hidden_state = hidden_state.detach()\n",
    "        output, hidden_state, loss = model(x[:, i], hidden_state=hidden_state, target=y[:, i])\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # gradient clipping\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "        total_loss += loss.item()\n",
    "        epoch_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        interval = 50\n",
    "        if (i + 1) % interval == 0 and i != 0:\n",
    "            tlossi.append(total_loss/(interval))\n",
    "            total_loss = 0\n",
    "        if epoch % 100 == 0 and i == 99:\n",
    "            with torch.no_grad():\n",
    "                val_hidden = torch.zeros(1, model.config.hidden_size).to(model.config.device)\n",
    "                for j in range(100):\n",
    "                    val_hidden = val_hidden.detach()\n",
    "                    output, val_hidden, loss = model(xv[:, j], hidden_state=val_hidden, target=yv[:, j])\n",
    "                    val_loss += loss.item()\n",
    "                print(f\"Epoch: [{epoch}/{num_epochs}], Loss: {epoch_loss/100}, Val Loss: {val_loss/100}\") \n",
    "                vlossi.append(val_loss/100)\n",
    "        total_grad_norm_squared = 0\n",
    "        for param in model.parameters():\n",
    "            if param.grad is not None:\n",
    "                grad_norm_squared = torch.sum(param.grad ** 2)\n",
    "                total_grad_norm_squared += grad_norm_squared\n",
    "        total_grad_norm = total_grad_norm_squared.sqrt().item()\n",
    "        gradients.append(total_grad_norm)\n",
    "        \n",
    "torch.save(model.state_dict(), 'shakespeare_rnn_3000_3r_res_1m.pth')                            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/TGe4hAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAykUlEQVR4nO3deXxV1b338e85mYEkECATBBIUGRImE0YRBxQVtdLaVnsdwLbehyqIpT4q2lZt1VhrlXqtKJZCkSq2TxzwQhVUEqRMMkTmABIIhIQwJiGBHJKs5w/MkQCBBM7JStif9+t1XnD23mev31mX6/l2r732chljjAAAACxx2y4AAAA4G2EEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWBtguoj+rqau3Zs0fh4eFyuVy2ywEAAPVgjFFpaani4+Pldtd9/aNZhJE9e/YoISHBdhkAAOA87Nq1Sx07dqxzf7MII+Hh4ZJOfJmIiAjL1QAAgPooKSlRQkKC93e8Ls0ijNQMzURERBBGAABoZs51iwU3sAIAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKxqFgvl+UvGqt1al1+sG1NiNahLW9vlAADgSI6+MpK1ZZ9mLNmhjXtKbJcCAIBjOTqMAAAA+wgjkoztAgAAcDBHhxGXy3YFAADA0WEEAADYRxiRZAwDNQAA2OLoMMIoDQAA9jk6jAAAAPsIIwAAwCpHhxEX02kAALDO0WEEAADY16Awkp6erv79+ys8PFzR0dEaNWqUcnJyzvqZzMxMuVyu016bN2++oMJ9ick0AADY06AwkpWVpQcffFDLli3TggULVFlZqREjRqisrOycn83JyVFBQYH31bVr1/Mu2lcYpAEAwL4Grdr7ySef1Ho/ffp0RUdHa9WqVRo2bNhZPxsdHa3WrVs3uEAAAHBxu6B7RoqLiyVJUVFR5zy2X79+iouL0/Dhw7Vw4cKzHltRUaGSkpJaL38yrE4DAIA15x1GjDGaOHGihg4dqpSUlDqPi4uL09SpU5WRkaH3339f3bp10/Dhw7Vo0aI6P5Oenq7IyEjvKyEh4XzLPDvGaQAAsK5BwzQnGzdunNauXavFixef9bhu3bqpW7du3veDBw/Wrl279NJLL9U5tDNp0iRNnDjR+76kpMR/gQQAAFh1XldGxo8frzlz5mjhwoXq2LFjgz8/aNAgbd26tc79ISEhioiIqPXyJ2bTAABgT4OujBhjNH78eH3wwQfKzMxUUlLSeTW6Zs0axcXFnddnfcnFOA0AANY1KIw8+OCDeuedd/TRRx8pPDxchYWFkqTIyEiFhYVJOjHEkp+fr5kzZ0qSJk+erMTERCUnJ8vj8WjWrFnKyMhQRkaGj78KAABojhoURqZMmSJJuvrqq2ttnz59usaMGSNJKigoUF5ennefx+PRI488ovz8fIWFhSk5OVlz587VyJEjL6xyH2KUBgAAexo8THMuM2bMqPX+0Ucf1aOPPtqgohoLS9MAAGAfa9MAAACrCCNiNg0AADY5OowwSgMAgH2ODiMAAMA+wohYmwYAAJscHUaYTQMAgH2ODiMAAMA+woiYTQMAgE2ODiOsTQMAgH2ODiMAAMA+wggAALCKMAIAAKxydBhhai8AAPY5OozUqM9qxAAAwD8IIwAAwCpHhxGGaQAAsM/RYaQGozQAANhDGAEAAFY5PIwwTgMAgG0ODyMnMEoDAIA9hBEAAGCVo8MIs2kAALDP0WGkBrNpAACwhzACAACscnQYYZQGAAD7HB1Gahjm0wAAYA1hBAAAWOXoMMJsGgAA7HN0GKnBbBoAAOwhjAAAAKscHUZczKcBAMA6R4eRGozSAABgD2EEAABY5egwwmwaAADsc3QY8WI6DQAA1hBGAACAVY4OIzWjNFwXAQDAHkeHEQAAYB9hBAAAWOXoMOL6djoN968CAGCPo8MIAACwjzACAACsIoxIMsynAQDAGsIIAACwijACAACscnQYqVmbhtk0AADY4+gwAgAA7COMAAAAqxwdRlzfrk7DKA0AAPY4OowAAAD7CCMAAMAqR4cRZtMAAGCfo8MIAACwjzACAACscnQY+XaUhrVpAACwyNFhBAAA2EcYAQAAVjk6jLi+G6cBAACWODqMAAAA+wgjAADAKkeHEZeLtWkAALDN0WEEAADYRxgBAABWOTqMeCfTsDgNAADWODqMAAAA+wgjAADAKsKIJEZpAACwx9lhxHXuQwAAgH81KIykp6erf//+Cg8PV3R0tEaNGqWcnJxzfi4rK0upqakKDQ1Vly5d9MYbb5x3wQAA4OLSoDCSlZWlBx98UMuWLdOCBQtUWVmpESNGqKysrM7P5ObmauTIkbryyiu1Zs0aPfHEE3rooYeUkZFxwcX7CqM0AADYE9iQgz/55JNa76dPn67o6GitWrVKw4YNO+Nn3njjDXXq1EmTJ0+WJPXo0UMrV67USy+9pNtvv/38qvYRF+M0AABYd0H3jBQXF0uSoqKi6jxm6dKlGjFiRK1tN9xwg1auXKnjx4+f8TMVFRUqKSmp9QIAABen8w4jxhhNnDhRQ4cOVUpKSp3HFRYWKiYmpta2mJgYVVZWav/+/Wf8THp6uiIjI72vhISE8y2zXphNAwCAPecdRsaNG6e1a9fq3XffPeexNQvS1ah54ump22tMmjRJxcXF3teuXbvOt8xz1OWX0wIAgAZo0D0jNcaPH685c+Zo0aJF6tix41mPjY2NVWFhYa1tRUVFCgwMVNu2bc/4mZCQEIWEhJxPaQAAoJlp0JURY4zGjRun999/X1988YWSkpLO+ZnBgwdrwYIFtbbNnz9faWlpCgoKali1fmKYTwMAgDUNCiMPPvigZs2apXfeeUfh4eEqLCxUYWGhjh496j1m0qRJuvfee73vx44dq507d2rixInatGmT/va3v2natGl65JFHfPctzhOjNAAA2NegMDJlyhQVFxfr6quvVlxcnPf13nvveY8pKChQXl6e931SUpLmzZunzMxM9e3bV7///e/16quvWp/WCwAAmoYG3TNi6jHtZMaMGadtu+qqq7R69eqGNNWomE0DAIA9jl6bhtk0AADY5+gwAgAA7COMAAAAqxwdRlibBgAA+xwdRgAAgH2EEdVvlhAAAPAPR4cRZtMAAGCfo8MIAACwjzAisTINAAAWOTqMMEoDAIB9jg4jAADAPsKIWJsGAACbnB1GmE4DAIB1zg4jAADAOsKIJMN8GgAArHF0GHF/O0rDPSMAANjj6DBSs1BeNWEEAABrHB1G3N77V0kjAADY4ugwUjOZprrabh0AADiZw8PIiTTCDawAANjj8DBy4k/uGQEAwB5HhxF3zZURwggAANY4OozU3L9qSCMAAFjj6DDivTJiuQ4AAJzM0WHku3tGiCMAANji8DDCPSMAANjm6DDi5soIAADWOTqMeG9gtVoFAADO5ugw4nbXDNMQRwAAsMXRYeS7qb1WywAAwNGcHUZcNav2kkYAALDF4WHkxJ9kEQAA7HF0GHF7r4xYLgQAAAdzdBhxef9GGgEAwBZHhxGujAAAYJ+jw4i894yQRgAAsMXRYYQrIwAA2OfwMHLiT7IIAAD2ODqMuBimAQDAOkeHETer9gIAYJ2jw0gNnsAKAIA9jg4jbh4HDwCAdY4OIzwOHgAA+xwdRrhnBAAA+xwdRmoeB2+Y3AsAgDXODiM89AwAAOscHkZO/MlzRgAAsMfRYYTHwQMAYJ+jw0hlVbUkKXvXYbuFAADgYI4OIx+v3WO7BAAAHM/RYaTcU2W7BAAAHM/RYYR7RQAAsM/RYWRkSqztEgAAcDxHh5HUzm0kScGBju4GAACscvSvsNt9YmpvKGEEAABrHP0rzNo0AADY5/AwcuLPKtIIAADWODyM1DyBlTACAIAtzg4jbh4HDwCAbc4OIyyUBwCAdY4OIwHfDtNUcWkEAABrHB1GXKzaCwCAdY4OIwE14zRiqAYAAFscHUZOyiIM1QAAYImjw0jNMI3EUA0AALY4OoycPEzDs0YAALDD0WHk5GEawggAAHY4PIwwTAMAgG0NDiOLFi3Srbfeqvj4eLlcLn344YdnPT4zM1Mul+u01+bNm8+3Zp85OYx8teOgxUoAAHCuBoeRsrIy9enTR6+99lqDPpeTk6OCggLvq2vXrg1t2udOHqbZsb/MXiEAADhYYEM/cNNNN+mmm25qcEPR0dFq3bp1gz/nTydfGQEAAHY02j0j/fr1U1xcnIYPH66FCxc2VrNn5XYTRgAAsK3BV0YaKi4uTlOnTlVqaqoqKir09ttva/jw4crMzNSwYcPO+JmKigpVVFR435eUlPi7TAAAYInfw0i3bt3UrVs37/vBgwdr165deumll+oMI+np6XrmmWf8XRoAAGgCrEztHTRokLZu3Vrn/kmTJqm4uNj72rVrl99rSukQ6fc2AADA6fx+ZeRM1qxZo7i4uDr3h4SEKCQkpBErkr7csk/9E6MatU0AAHAeYeTIkSPatm2b931ubq6ys7MVFRWlTp06adKkScrPz9fMmTMlSZMnT1ZiYqKSk5Pl8Xg0a9YsZWRkKCMjw3ffwgfeW7lLE0d0O/eBAADApxocRlauXKlrrrnG+37ixImSpNGjR2vGjBkqKChQXl6ed7/H49Ejjzyi/Px8hYWFKTk5WXPnztXIkSN9UD4AAGjuXMY0/UVZSkpKFBkZqeLiYkVERPj03ImPz5UkxUSEaPkT1/n03AAAOFl9f78dvTYNAACwjzACAACsIox8a29JxbkPAgAAPkcYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYSRk2zdW2q7BAAAHIcwcpJ3VuTZLgEAAMdxfBi5MTnW+/eNe0osVgIAgDM5PoxER4R4/74896DFSgAAcCbHh5EfpSbYLgEAAEdzfBjpGtPKdgkAADia48NIaFCA7RIAAHA0x4cRAABgF2EEAABYRRgBAABWEUZOsSbvkO0SAABwFMLIKX73vxttlwAAgKMQRk6xJu+w7RIAAHAUwoiklA4Rtd4fKvNYqgQAAOchjEi6Z1DnWu9Tn11gqRIAAJyHMCIppUNkrffVRpowe42lagAAcBbCiKTk+MjTtn2UvUfGGAvVAADgLISRs1jBKr4AAPgdYeQsPszOt10CAAAXPcLIt7Y+d9Np295dsUtlFZUWqgEAwDkII98KCjhzVyQ/9WkjVwIAgLMQRk5yR1rCGbd/tYN7RwAA8BfCyEn+8MPeZ9z+ozeWqqKyqpGrAQDAGQgj9dTt15/opU9zbJcBAMBFhzByirYtg+vc99rCbY1YCQAAzkAYOcXSScPPuv/aP2U2TiEAADgEYeQUwYFurf7N9XXu376vTGt3H268ggAAuMgRRs4g6ixDNZL0vdf+I09ldSNVAwDAxY0wUofs39Z9dURiZV8AAHyFMFKH1i2C9fVTI+rcX3qsUjf9+ctGrAgAgIsTYeQsIsOCNPTSdnXu31RQwnANAAAXiDByDrN+PvCs+9/I+qaRKgEA4OJEGKmH+69MqnPfywu2NGIlAABcfAgj9TDpph5n3f/c3I2NVAkAABcfwkg9uN0u5aaPrHP/W1/mKvHxuVqTd6gRqwIA4OJAGKknl8t1zmO+//oSfbZxryTJGKMNe4p11MMCewAAnA1hpAGu7Fr3zJoaP5+5UgeOVChp0jzd/OpiDXjus0aoDACA5osw0gBv/+zsM2tqpD77XQAprahU4uNzZYzxV1kAADRrhJEG+sfPByo8JFBfPnqNVv76unp/7v6Zq2SMIZQAAHAKl2kGv44lJSWKjIxUcXGxIiIibJdzmsTH5zbo+F9df5nGD+/qp2oAAGga6vv7zZURC/60YIuKjx6XJGXmFOnuvy5XuadSlVU8zRUA4DxcGfGBzYUlunGyb9ap2fDMDWoZEuiTcwEAYBNXRhpR99gIbf79jT4516It+3xyHgAAmgvCiI+EBgUoN32kNv/+RiVEhZ33eX7xj9VanXdIVdVN/oIVAAA+QRjxIZfLpdCgAP17wrALOs8PXl+iS56Ypyc/WKfqU0LJ8apqHThScUHnBwCgKeGeET9Zn1+sW/5nsff9jPv6a8z0r87rXB88MERf7TiozzcVaXnuQUnSTwYkqE/H1rpzQCef1AsAgK/V9/ebMOJnnspqBQW45HK5VFx+XH1+N1+SlNi2hXYcKL/g87/z84Eacum5nwwLAEBjI4w0YZVV1QoMcOtwuUd9f7fggs/3xa+uUmW10dtLd2rctZcqJiLUB1UCAHBhCCPNRGVVtS598t9+OXe/Tq21Ju+wJGnsVZeoa3Qr3Z7a0S9tAQBwKqb2NhOBAW7d3DvO+z7zkat9du6aICJJb2R9o1/962vtPFAmY4y2FZVq2uJc3f3X5dpbcsxnbQIA0FBcGWki/vjpZhUfPa5nR/WSJBljtKf4mB74x2p9veuw39v/7S099ZMBnRQWHOD3tgAAzsAwzUVm6B++0O5DR/3ezk8GJKhbTLh2HzqqJ2/uIZfL5fc2AQAXJ78N0yxatEi33nqr4uPj5XK59OGHH57zM1lZWUpNTVVoaKi6dOmiN954o6HNOl5i25Zn3H5zrzhl//Z6uX2UGd5dsUtPf7xRf12cq9unLNHwP2VqYU6RjDEqKj2mVTsP+qYhAAC+1eBFUMrKytSnTx/dd999uv322895fG5urkaOHKn7779fs2bN0n/+8x898MADat++fb0+jxNe/GFv/e7jjbrvikQZSSGBbnVs00JtWwbL7XZpe/rN2ldaofbhIZKk3P1luualzAtqc/W395zcd8rzUUKD3Epo00L9k6L03KgUrp4AAC7IBQ3TuFwuffDBBxo1alSdxzz22GOaM2eONm3a5N02duxYff3111q6dGm92mGY5vw8PHuNPsze4/d2kuMjNPehK/3eDgCgeanv77ffl4ddunSpRowYUWvbDTfcoGnTpun48eMKCgo67TMVFRWqqPjukeclJSX+LvOiNPnOfpp8Zz9JJ26I/WxTkQZ2iVJEaJA8ldX6wyebNW1x7gW3s2FPiXo//aleuL23Vu88pHnrCjTokrZ6+cd9VVR6TCtyD+qG5FgFBTB5CwBwOr+HkcLCQsXExNTaFhMTo8rKSu3fv19xcXGnfSY9PV3PPPOMv0tzFJfLpet7fvd/h+BAt35zS089dmN3Pf7+WlVWGY0e0lmrdx7Wc/M2neVMZ1ZyrFIP/GO19/37q/P1/ur8WscEuF1a+vi1ahUaqBbBgfJUVutgmUexkTykDQCczO9hRNJp9xTUjAzVda/BpEmTNHHiRO/7kpISJSQk+K9ABwsOdOvlH/f1vk/tHKVrurfXXxZ+o5tSYjVreZ4Wbdnnk7aqqo0GPP+5JOn/XNVFX27Zr40FJZr30JXqGc/wGwA4ld/DSGxsrAoLC2ttKyoqUmBgoNq2bXvGz4SEhCgkJMTfpaEOl0aH65U7+kqSRiTH6nC5R6t2HtL4d9eo3FPlkzbezNru/fvIV7/Utuduktvl0lc7Dqp7XIQiw04fvgMAXJz8HkYGDx6sjz/+uNa2+fPnKy0t7Yz3i6Dpad0iWMN7xGjd0zdoTd4hRYYFqdxTpdz9ZXr4vWyftHHqI/FfvL23yj2VGnNFUq3txhgdKPOoorJaHVqH+aRtAIBdDQ4jR44c0bZt27zvc3NzlZ2draioKHXq1EmTJk1Sfn6+Zs6cKenEzJnXXntNEydO1P3336+lS5dq2rRpevfdd333LdAoAtwupSVGed/3SWitm3vHqeu3QeKX112mW/vEafG2/SoqqdBrC7fVdapzejRjrSQpLDhApccq9c2+MgUFuJS1ZZ92frva8dqnRygilEALAM1dg6f2ZmZm6pprrjlt++jRozVjxgyNGTNGO3bsUGZmpndfVlaWfvnLX2rDhg2Kj4/XY489prFjx9a7Tab2Nm3r84u1PPegxgxJVMApT1+rqjYKcLuU+Phcv7S9+jfXK6plsF/ODQC4MDwOHk3KoTKPXvw0R++uyPPL+W9MjtV/DeykyZ9t0RMje9S6ggMAsIMwgibpcLlHOYWlumPqMknSjhdu1pJv9uu/3lru03be/tkAvbsiT4/d2F0dWofpYJlHf/w0R8erqjXk0nb6cRqzswDA3wgjaNLW7j6ssKAAdY0JlyRt2FOso54qvTQ/R8u2+3/9my7tW+pPP+qj7rERrFQMAH7it4XyAF/o3bG1N4hIUnJ8pNISozTjvgGK/nZ9nYjQ0++vHtU33iftb99Xpu+/vkSj/7bCu80Yo3JPpU/ODwCoP66MoMnxVFYrwO1SgNul41XVMubEw9nKPZVqERyo7fuOqF14iK59KUv7j1Sc+4QN9L/jh6pnXISKjx5XxurdurVPvGIieEosADQUwzRwhI+y8zVhdrb/23nwCqV0iFSA26XKqmpVVhuFBjG8AwBnwzANHOG2vh2044Wb9eY9qRp2WXv9bGjSuT90Pu385T96aX6OJOnmVxcr7dnPGNIBAB/hygguWh9l5yvvQLn+tGCL39p4ZMRlio0M05db9+kPt/fmagkAnIRhGuAkVdVGeQfLdc1LmXpiZHel/3uz/PEv/4MHhuij7D2asWSH1vzmerXhgWwAHIwwApzFpoISPf7+Oj0y4jJd2bW9pmR+oz98stnn7ax/5ga1CmmUxbEBoMkhjAANVF1ttCz3gJLjIlVRWaX7ZnyluMhQfbap6ILOu/35kZKkHQfKFBkWpLatWJEagDMQRgAf2XmgTMVHj6tXh0glTZp3wecbf+2l2ldaoWduS1ZIIPeYALh4EUYAPzleVa3ZX+3Sbz5c75PzBbpdWjLpWhWXH6/1IDhJyjtQrpU7D+q2vh1OW4QQAJq6+v5+M5gNNFBQgFt3D+ykiuNV6pPQWut2F+t3/7vxvM9XWW004LnPve+7x4YrIaqFbkqJ1cR/fi1J2nP4qMZd2/WCaweApogrI4APJT4+12/n7hkXoau6tdeE4V2ZQgygWWCYBrCg3FOpopITj6i/f+ZKbS064pd2vn5qhCoqq/Svlbs1f0OhZv5soPIOlCskyK3LThnqAQBbCCNAE7Ct6IjmrSvQy3588NqpctNHam9JhR58Z7XuSEvQj/snNFrbAHAywgjQhCzeul93T1su6cRTW1+a33jh5La+8Zp8R1+5XNwAC6BxEUaAJmx13iHtPFCmr3Yc0jvL8xqlzeVPDFdUy2AFBbhVVHpMN7yySH/6cR9d2z2mUdoH4DyEEaCZKC4/rhYhAd5H1nsqq/X5piIFBrj0x09zGqWG39+WrDJPlb7YXKS/3zdAYcHcIAvgwhFGgIvAqp2HdPuUJZKkH6V21Df7jmh13mG/tnn75R310PBL1SmqBUM7AC4IYQS4SCzbfkCdoloovnWYJGn3oXI9PDtbK3ceapT2b0iO0Rt3pxJMADRYfX+/3Y1YE4DzMKhLW28QkaSObVro//1iiDY8c4Ou7NpOL/ygl1/b/3TDXq3PL1G5p1JV1U3+f7sAaIa4MgJcRNbuPqydB8p1S+84Lcwp0k9nrPR5G6t+fZ1emp+j977apdfvulw3psT5vA0AFweGaQBIkrbvO6Jr/5Tlt/N3addSr/3X5YqOCFE7ViQGcBLCCACvmuecXNm1nd66N02j/7ZCy3MP+qWtuMhQxUSE6mdDkzSyVxwL/AEORhgBcFZvLdqut5ftVN7Bcr+2c3W39ppx3wC/tgGgaSKMAKi341XV+ufKXQoPDdJD767xWztv3Zum63vGqKrayO0SM3SAixxhBMB5q6is0svzt+jNRdv92s70+/orIjRIqZ3b+LUdAHYQRgBcsI+/3qNXP9+qALdLmwtL/drWW/emKaplkJ78YL3++MM+6tUx0q/tAfA/wggAnyr3VKraSP/3X1/r5t5x2l9aoSlZ32hvSYVf2vthakf9bGiS9h+p0ICkKIUEBshTWa3gQB6PBDQXhBEAjWLH/jJ9tmmvjnqqtGFPiUb2jvPLfSf/PayLpi7arh+mdtTvbktWi+BAn7cBwLcIIwCseXnBFr36+Va/tjGyV6weGt5VYUEBSmjTQm6mEANNDmEEgFXlnkq1CA7U1r2l+vGbSxUbGaZNBSV+aeuHqR317KgUlR6rVPvwEBljmKkDNAGEEQBNRk04uOalTOXuL2u0dm/pHaenbk1W+3CeDAvYQBgB0OR4Kqv1YXa+hlzSVh3btJAkFZUc079W7dbfl+xQUal/boZd+/QIjXh5kQpLjnmfdQLA/wgjAJqdvSXHNPD5z/3eTnJ8hK7tHq07+id4QxEA3yOMAGiWthWVas/hY7r3byv0wNWX6Mqu7fXhmnwt3rZf+YeP+ry9nwxI0OghiZq3tkCjhySqLYv9AT5DGAHQrJ3pJtTjVdXK3V+mEa8s8lu7z45K0YjkGEWHh/qtDcApCCMALlrGGB2pqNSx49Xq/9xnfmvne33i9aO0jio+elwxEaFK69yGWTpAAxBGADhCRWWV3C6XggLc+mLzXv10xkq/tfXQtZfql9dfRiAB6okwAsCRSo4d19pdxbp72nK/tdEqJFB/G9NfA5KivNt4tglwuvr+fvM8ZQAXlYjQIA3t2k6j+sbrw+w9fmnjSEWlfvzmUknSD/p10P4yjxZt2ac+HSP10bihfmkTuJhxZQTARamyqlqzlu3U0x9vbNR2o1oGa/Z/D9JlMeE6UlGplsEBXDGBYzFMAwCnMMbo5QVb9D9fbFNMRIjfVhw+1Y4XbtaBIxVyu1xq0zK4UdoEmgLCCADUgzFGFZXVum/6V1q6/YD+z7AuenPRdp+2kf6DXpr0/jpJ0oThXXXXoE5MHYYjEEYA4DwZY/T3JTv8OsQzqm+8XrmjL0M4uKgRRgDgAh31VKncU6nIsCBd+uS/fX7+4AC3+nVqree+30uXRrfy+fkB2+r7++1uxJoAoFkJCw5Q21YhCgxw6/e3JevHaR310yuSah0THHj+/xn1VFVree5BXfdylnYfKtcrC7Yo8fG52lxYomPHqy60fKDZ4MoIAJwHT2X1aUEk8fG5Pm3js4lXKS4yVIEBLoUEBvj03EBj4DkjAOBHZ7oi8ofbe+mxjHU+a+O6l7POuH3uQ0PVNTr8gq7KAE0JV0YAwIeOV1Vr54EyXRodrnJPpXr+9lO/tRUc4FZc61D16hCpP9zeWy1D+N+XaFq4gRUAmohl2w/ozqnL/N5Oh9Zh+uKRq7xDOpVV1dp3pEJxkWF+bxs4E8IIADQh6/OL9Y/leXp3RV6jt/3Ozwfq8s5tFBLoZioxGhVhBACaoL0lx1RVbRTfOkwLNxfpvhlfNWr7cx8aquT4SEnS4XKPIsOCCCjwG8IIADQTW/aW6sut+9WhdajGzlrt9/batgxW34TW+nxzka7s2k5v/2yg39uEMxFGAKAZqq42mrV8pzbuKdGP+yeoY5swDXjuc7+3O+O+/hoz/SsNuaStZtw3QDsOlKl1iyAeW48LQhgBgItEZVW18g8fVVhwgIyRBj7v/3BS45becZq/Ya+m3H25hveIabR2cXEgjADARaq62uhQuUdRLYN1z7QVWrxtf6PXEBzgVtajVys2IrTWPScFxUdVUHxMl3dq0+g1oekhjACAQxhj5HK5dNRTpR6//cRKDcnxEfrZ0CRN/OfXkqTuseEaMyRRdw7oZKUeNA2EEQBwoOXbD2jiP79W/8Q2KvdUaf7GvVbr+fnQJI0ekqh/rdqtVz/fqj4JrfXRg1dYrQmNhzACAPDyVFYr0O1Sr6c/VZnH7iJ8t/WN15/v7Keanx+mFl+8CCMAgNOUeyo1a9lOPT9vs+1SvP53/FCldIj0vs/edVg79pdpVL8OFquCLxBGAAB1OnCkQi2CA7V292Eld4hU7r4yzV1XoDeyvrFWU5sWQQoPDVLewXJJUsYvBiu1c5S1enDhCCMAgPO2dW+prn9lke0yJEm9OkTqmduSFRMRqvjIUM35eo8+yt6jyXf2VXhIoLYVHVGX9q0U4Ga4p6khjAAALsjBMo/+tjhXdw3qpLjIMGXmFGnM9MZ9fH1DrP7N9dpWdETPzt2oZ76XrH5ML7aOMAIA8ItyT6VCAgP0+aa9+u+3V3m3p/+glwJcLj2asdZidd/5/agUuV3SLb3i5amq1vGqasW3ZgXjxkQYAQD4lTFGq/MOKTIsSPuPeDSoS1tJ0qEyjzYXlurDNfl6b+Uuy1We7o60BI279lJFR4Rob3GFEqLCmNHjJ4QRAECTcKjMo+W5B3Vdj2i5XS51eWKeJOn+K5P01pe5lquT2rUK1m9u6amYiFDdN/0rdW7bQo/d1F3XdIuWJBUfPa6QQLdcLmn+hr3qEReuS9q3IsDUg1/DyOuvv64//vGPKigoUHJysiZPnqwrr7zyjMdmZmbqmmuuOW37pk2b1L1793q1RxgBgIuPMUZZW/Z570N5cmQPPTdvk+Wqzs9Dw7vq3sGd9U3REb331S49eXMPRYYFKTDALem7p+Q6jd/CyHvvvad77rlHr7/+uq644gq9+eab+utf/6qNGzeqU6fTH/tbE0ZycnJqFdK+fXsFBAT49MsAAJqf/Ucq1CokUKFBJ34TCoqPalNBibbsPaKru7XXityD+mrHIX389R7LlTbcmCGJOna8SrO/OjFc9d/Duig4wK3RQxIVERaoQLdbbtd3D37bdbBcz3y8UWOv6qKUDpFan1+sqJbB6tK+lfIOlCs6IsTbT82B38LIwIEDdfnll2vKlCnebT169NCoUaOUnp5+2vE1YeTQoUNq3bp1Q5ryIowAACqrqvXPlbu1auchdY8N19e7D6uyyuiTDYW2S/OJJ0Z2r9fD6P7vDd1098DO+njtHqV2bqPn523S2t3FKj56XM+OStENybH69/oC3do7XntLj6myyig5PkJb9h5RQlSYqqqNtuw9on4JreV2u3TseJUC3S7vVRxf8ksY8Xg8atGihf71r3/p+9//vnf7hAkTlJ2draysrNM+UxNGEhMTdezYMfXs2VO//vWvzzh0U6OiokIVFRW1vkxCQgJhBABwRh9l52vC7GwNSIzSih0Hvdv7dWqtNXmH7RXWjLxyRx99v19Hn56zvmEksCEn3b9/v6qqqhQTE1Nre0xMjAoLz5xM4+LiNHXqVKWmpqqiokJvv/22hg8frszMTA0bNuyMn0lPT9czzzzTkNIAAA52W98Ouq3vd4+PP/kejaXfHNCGPcX6fFORusa0UrfYcP3zq136enexrXKbpMLiinMf5CcNujKyZ88edejQQUuWLNHgwYO925977jm9/fbb2ry5fmsd3HrrrXK5XJozZ84Z93NlBADgbzWBJXd/mVbuOKjMnH0a2StOQQEu/fajDSosOWa7xEbVN6G1PvTxisp+uTLSrl07BQQEnHYVpKio6LSrJWczaNAgzZo1q879ISEhCgkJaUhpAAA0SM2Vk6R2LZXUrqV+lJbg3TciOVaHyz0q91QpONCtdq1O/CbtPlSuT9YX6tm5mzQgKUq9OkRq2uIT05O7xYQrZ29p438RH6mZymxDg8JIcHCwUlNTtWDBglr3jCxYsEC33XZbvc+zZs0axcXFNaRpAAAaVesWwWrdova2jm1a6OdXdtE9gzsrJPDErJbf3NLTu3/DnmJVVhmFhwaqS/tWWrnjoJ6bt0ndY8P17opd354jTLsPHW2071Ff46+91FrbDQojkjRx4kTdc889SktL0+DBgzV16lTl5eVp7NixkqRJkyYpPz9fM2fOlCRNnjxZiYmJSk5Olsfj0axZs5SRkaGMjAzffhMAABpJTRA5VXJ8ZK33aYlR+uCBE0MfE4ZfpratghV00qyVisoq/ebD9frnyt2aNjpNJceO6y8Lv9Eff9hbyfGRCg787lhjjHL2lqpTVAuFBQXoX6t269H/t1Z3pCXo7kGddetri+us96rL2stTWa3AAJeu7R6tZz7eWGv/m/ekym1xocHzfujZiy++qIKCAqWkpOiVV17x3ow6ZswY7dixQ5mZmZKkF198UVOnTlV+fr7CwsKUnJysSZMmaeTIkfVuj6m9AACc27HjVbWeQ1JVbc64mnFFZZVenr9FLYIDNf7aS/0WRHgcPAAAsKq+v9++f8IJAABAAxBGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVgXaLqA+ahYWLikpsVwJAACor5rf7Zrf8bo0izBSWloqSUpISLBcCQAAaKjS0lJFRkbWud9lzhVXmoDq6mrt2bNH4eHhcrlcPjtvSUmJEhIStGvXLkVERPjsvBcr+qv+6Kv6o6/qj76qP/qq/vzZV8YYlZaWKj4+Xm533XeGNIsrI263Wx07dvTb+SMiIvjH2gD0V/3RV/VHX9UffVV/9FX9+auvznZFpAY3sAIAAKsIIwAAwCpHh5GQkBA99dRTCgkJsV1Ks0B/1R99VX/0Vf3RV/VHX9VfU+irZnEDKwAAuHg5+soIAACwjzACAACsIowAAACrCCMAAMAqR4eR119/XUlJSQoNDVVqaqq+/PJL2yX51aJFi3TrrbcqPj5eLpdLH374Ya39xhg9/fTTio+PV1hYmK6++mpt2LCh1jEVFRUaP3682rVrp5YtW+p73/uedu/eXeuYQ4cO6Z577lFkZKQiIyN1zz336PDhw37+dr6Vnp6u/v37Kzw8XNHR0Ro1apRycnJqHUN/nTBlyhT17t3b+8CkwYMH69///rd3P/1Ut/T0dLlcLj388MPebfTXd55++mm5XK5ar9jYWO9++qq2/Px83X333Wrbtq1atGihvn37atWqVd79Tbq/jEPNnj3bBAUFmbfeests3LjRTJgwwbRs2dLs3LnTdml+M2/ePPPkk0+ajIwMI8l88MEHtfa/8MILJjw83GRkZJh169aZO+64w8TFxZmSkhLvMWPHjjUdOnQwCxYsMKtXrzbXXHON6dOnj6msrPQec+ONN5qUlBSzZMkSs2TJEpOSkmJuueWWxvqaPnHDDTeY6dOnm/Xr15vs7Gxz8803m06dOpkjR454j6G/TpgzZ46ZO3euycnJMTk5OeaJJ54wQUFBZv369cYY+qkuK1asMImJiaZ3795mwoQJ3u3013eeeuopk5ycbAoKCryvoqIi73766jsHDx40nTt3NmPGjDHLly83ubm55rPPPjPbtm3zHtOU+8uxYWTAgAFm7NixtbZ1797dPP7445YqalynhpHq6moTGxtrXnjhBe+2Y8eOmcjISPPGG28YY4w5fPiwCQoKMrNnz/Yek5+fb9xut/nkk0+MMcZs3LjRSDLLli3zHrN06VIjyWzevNnP38p/ioqKjCSTlZVljKG/zqVNmzbmr3/9K/1Uh9LSUtO1a1ezYMECc9VVV3nDCP1V21NPPWX69Olzxn30VW2PPfaYGTp0aJ37m3p/OXKYxuPxaNWqVRoxYkSt7SNGjNCSJUssVWVXbm6uCgsLa/VJSEiIrrrqKm+frFq1SsePH691THx8vFJSUrzHLF26VJGRkRo4cKD3mEGDBikyMrJZ921xcbEkKSoqShL9VZeqqirNnj1bZWVlGjx4MP1UhwcffFA333yzrrvuulrb6a/Tbd26VfHx8UpKStKdd96p7du3S6KvTjVnzhylpaXpRz/6kaKjo9WvXz+99dZb3v1Nvb8cGUb279+vqqoqxcTE1NoeExOjwsJCS1XZVfO9z9YnhYWFCg4OVps2bc56THR09Gnnj46ObrZ9a4zRxIkTNXToUKWkpEiiv061bt06tWrVSiEhIRo7dqw++OAD9ezZk346g9mzZ2v16tVKT08/bR/9VdvAgQM1c+ZMffrpp3rrrbdUWFioIUOG6MCBA/TVKbZv364pU6aoa9eu+vTTTzV27Fg99NBDmjlzpqSm/2+rWaza6y8ul6vWe2PMaduc5nz65NRjznR8c+7bcePGae3atVq8ePFp++ivE7p166bs7GwdPnxYGRkZGj16tLKysrz76acTdu3apQkTJmj+/PkKDQ2t8zj664SbbrrJ+/devXpp8ODBuuSSS/T3v/9dgwYNkkRf1aiurlZaWpqef/55SVK/fv20YcMGTZkyRffee6/3uKbaX468MtKuXTsFBAScluKKiopOS41OUXOH+tn6JDY2Vh6PR4cOHTrrMXv37j3t/Pv27WuWfTt+/HjNmTNHCxcuVMeOHb3b6a/agoODdemllyotLU3p6enq06eP/vznP9NPp1i1apWKioqUmpqqwMBABQYGKisrS6+++qoCAwO934X+OrOWLVuqV69e2rp1K/+2ThEXF6eePXvW2tajRw/l5eVJavr/zXJkGAkODlZqaqoWLFhQa/uCBQs0ZMgQS1XZlZSUpNjY2Fp94vF4lJWV5e2T1NRUBQUF1TqmoKBA69ev9x4zePBgFRcXa8WKFd5jli9fruLi4mbVt8YYjRs3Tu+//76++OILJSUl1dpPf52dMUYVFRX00ymGDx+udevWKTs72/tKS0vTXXfdpezsbHXp0oX+OouKigpt2rRJcXFx/Ns6xRVXXHHa4we2bNmizp07S2oG/80671tfm7maqb3Tpk0zGzduNA8//LBp2bKl2bFjh+3S/Ka0tNSsWbPGrFmzxkgyL7/8slmzZo13OvMLL7xgIiMjzfvvv2/WrVtnfvKTn5xx2lfHjh3NZ599ZlavXm2uvfbaM0776t27t1m6dKlZunSp6dWrV7ObJveLX/zCREZGmszMzFrTCsvLy73H0F8nTJo0ySxatMjk5uaatWvXmieeeMK43W4zf/58Ywz9dC4nz6Yxhv462a9+9SuTmZlptm/fbpYtW2ZuueUWEx4e7v3vNH31nRUrVpjAwEDz3HPPma1bt5p//OMfpkWLFmbWrFneY5pyfzk2jBhjzF/+8hfTuXNnExwcbC6//HLvtM2L1cKFC42k016jR482xpyY+vXUU0+Z2NhYExISYoYNG2bWrVtX6xxHjx4148aNM1FRUSYsLMzccsstJi8vr9YxBw4cMHfddZcJDw834eHh5q677jKHDh1qpG/pG2fqJ0lm+vTp3mPorxN++tOfev//qH379mb48OHeIGIM/XQup4YR+us7Nc/BCAoKMvHx8eYHP/iB2bBhg3c/fVXbxx9/bFJSUkxISIjp3r27mTp1aq39Tbm/XMYYc/7XVQAAAC6MI+8ZAQAATQdhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFX/HycECVJr21HeAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min tes loss: 0.47102188974618914\n",
      "Fin tes loss: 0.49916060090065\n",
      "Min val loss: 1.9106521093845368\n",
      "Fin val loss: 4.095321617126465\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot((tlossi[:]))\n",
    "# clipped_lossi = []\n",
    "# for l in tlossi:\n",
    "#     if l < 3:\n",
    "#         clipped_lossi.append(l)\n",
    "# plt.plot(clipped_lossi)\n",
    "plt.show()\n",
    "print(f\"Min tes loss: {min(tlossi)}\")\n",
    "print(f\"Fin tes loss: {tlossi[-1]}\")\n",
    "print(f\"Min val loss: {min(vlossi)}\")\n",
    "print(f\"Fin val loss: {vlossi[-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When ran with 1000 epochs without residuals the min loss was: 1.612 \\\n",
    "When ran with 1000 epochs with residuals the min loss was: 1.601 \\\n",
    "When ran with 2000 epochs with residuals the min loss was: 1.589 \\\n",
    "note* while looking at the loss graph it seems like the loss can continue to decrease with this setup and more epochs \\\n",
    "When ran with 2000 epochs with residuals and two hidden layers the min loss was: 1.529 \\\n",
    "First going to get the val loss for this run and see how it is \\\n",
    "The same test with val loss now being calculated. MIN Tloss: 1.516 MIN VLoss: 1.826 \\\n",
    "\\\n",
    "To test the impact of residuals I'm going to remove them here and see how that affects the performance \\\n",
    "No Residuals: MIN TLoss: 1.516 MIN VLoss: 1.826 \\\n",
    "\\\n",
    "Making the model more parameters and deeper from 20000 params to 700000 and gradient clipping\\\n",
    "old, n_embd=64 n_hidden=64 \\\n",
    "new, n_embd=256 n_hidden = 512 \\\n",
    "New test with 2000 epochs, MIN TLoss: 1.377 FIN VLoss: 2.778 \\ \n",
    "\\\n",
    "Final test for now \\\n",
    "1 million param, 3 hidden, 3k epochs, p.s. found a bug in the model so everything before is a little weird \\\n",
    "MIN TLoss: 0.471 FIN VLoss: 4.09 \\\n",
    "So this is obviosly just memorizing the dataset at this point and the limits of char NLP is evident\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I sense of my love, to whom I am not born to out in your true love of young.\n",
      "Thus have return in your perfumed the herd\n",
      "As a death my days should it depends of blood warmion this glutton by your shadow kind,\n",
      "Harsh, still without all deeds must I under than a for nor than of my brain\n",
      "Full change into my deeds thee,\n",
      "This sin there beauty being made)\n",
      "Shall beauty was every alien pen hath more enlarged hooks of the blind do not summer's shope to present'st friend's oppress hhants by.\n",
      "\n",
      "\n",
      "\n",
      "Since first the world will be the mortal wanting youth, some into my beloved, yet where thou art.\n",
      "Gen but one, and the read fleece tang a number on me thought\n",
      "To think of them me well proud of agers with flower from Time's quicked the clock that thou for worthiness give them thy mother;  \n",
      "Withister still,\n",
      "Which through him be grieved that flowers I better becomimy profitless usurer weeds.\n",
      "\n",
      "\n",
      "\n",
      "For walks treads w"
     ]
    }
   ],
   "source": [
    "# model testing\n",
    "\n",
    "\n",
    "hidden_state = torch.zeros(1, model.config.hidden_size).to(model.config.device)\n",
    "output = torch.tensor([20]).to(model.config.device)\n",
    "print(itos[20], end='')\n",
    "response_length = 900\n",
    "for _ in range(response_length):\n",
    "    output, hidden_state, loss = model(output, hidden_state=hidden_state)\n",
    "    probs = F.softmax(output.view(1, -1), dim=1)\n",
    "    output = torch.multinomial(probs, num_samples=1)\n",
    "    print(itos[int(output.item())], end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
